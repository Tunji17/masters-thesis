% Chapter 1

\chapter{Introduction} % Main chapter title

\label{Chapter1} % For referencing the chapter elsewhere, use \ref{Chapter1} 

%----------------------------------------------------------------------------------------

% Define some commands to keep the formatting separated from the content 
\newcommand{\keyword}[1]{\textbf{#1}}
\newcommand{\tabhead}[1]{\textbf{#1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\file}[1]{\texttt{\bfseries#1}}
\newcommand{\option}[1]{\texttt{\itshape#1}}

%----------------------------------------------------------------------------------------

\section{Background and Context}

\subsection{Clinical Documentation in Healthcare}

Healthcare providers generate vast amounts of data through electronic health records (EHRs), which serve as longitudinal digital records of patient information. EHR data comes in both \textbf{structured} and \textbf{unstructured} formats. Structured data refers to information stored in predefined fields (e.g. patient demographics, vital signs, lab results, diagnoses, medications) that can be readily queried. In contrast, \textbf{unstructured data} consists of free-form text and other formats such as clinical narratives, discharge summaries, radiology reports, and even medical images. Free-text clinical notes are a natural and expressive way for clinicians to document patient encounters, often capturing nuanced details of a patient's condition and care that do not fit neatly into structured fields. For example, a physician's narrative note may describe symptom severity or social circumstances in richer detail than any diagnostic code.

Notably, unstructured content constitutes the majority of clinical documentation. By some estimates, \textbf{up to 80\% of healthcare data is unstructured} text or images \parencite{Kong2019}. This means that most recorded medical information—such as physician notes, operative reports, and imaging studies—does not reside in tabular databases but in narrative form. Such unstructured clinical documentation is immensely valuable, as it provides a "glimpse into the physician's brain," revealing clinical reasoning and context beyond what structured data can convey. However, because it lacks a predefined format, unstructured data is not directly usable by computers or standard query tools. Healthcare organizations are therefore faced with the challenge of leveraging these abundant narrative documents to improve patient care, research, and decision-making.

\subsection{Challenges with Unstructured Clinical Data}

Working with unstructured clinical text is inherently challenging. Free-text medical notes are \textbf{difficult for automated systems to interpret} due to their lack of consistent structure and the complexities of natural language. Unlike structured entries, a narrative note may contain context-dependent information, ambiguous terminology, and diverse writing styles. Indeed, clinical text often includes \textbf{misspellings, grammatical errors, shorthand and abbreviations, and incomplete sentences}, all of which increase the difficulty of parsing and analyzing the data. Important details might be embedded in long narrative paragraphs, making it hard to extract specific facts without advanced text processing. As a result, analyzing unstructured EHR data has traditionally required labor-intensive manual review or bespoke rule-based systems.

Another challenge is the inherent variability and informality of clinical language in practice. Clinical notes are not written with standardized vocabulary or ontology usage; different clinicians may describe the same concept in varied ways. Moreover, notes reflect real-world patient cases with all their complexity. In contrast to controlled text like medical textbooks, \textbf{EHR narratives present irregular, multifaceted data}: patients often have multiple comorbidities, and documentation may intermix relevant and irrelevant details. The informal style (e.g. telegraphic phrases, local acronyms) and the fact that observations are filtered through each clinician's perspective make consistent information extraction problematic. These factors can confound algorithms attempting to identify entities (such as diseases or medications) and their relationships from raw text.

In addition, \textbf{scale and integration issues} pose further hurdles. Hospitals generate hundreds of notes per day, leading to information overload; processing this volume is complex and time-consuming. The heterogeneity of data sources (notes, images, labs, etc.) adds complexity in combining unstructured with structured data. Data quality issues like typos or missing context can propagate errors in analysis. All these challenges underscore why much of the unstructured clinical data remains underutilized. However, given the wealth of knowledge contained in narrative texts, there is strong incentive to overcome these difficulties through advanced computational methods. In recent years, the field of \textbf{clinical natural language processing (NLP)} has gained wide interest as researchers apply machine learning and language models to parse and derive meaning from clinical text. These developments set the stage for transforming unstructured clinical documents into structured forms that can drive insights.

%----------------------------------------------------------------------------------------

\section{Research Motivation}

\subsection{The Need for Structured Information Extraction}

Unlocking the value in unstructured clinical text is a key motivation for this research. While clinicians rely on narrative documentation for communication and decision recording, secondary use of this data (for analytics, decision support, or research) is limited by its unstructured nature. In order for healthcare information systems to fully utilize EHR data, the free-text portions must be converted into a structured, machine-readable form. \textbf{Information Extraction (IE)} is the crucial NLP task aimed at addressing this gap: it automatically identifies and encodes important pieces of information from unstructured text. By applying IE to clinical narratives, one can populate databases or knowledge bases with structured representations of the same information (e.g. identifying a drug name and dosage mentioned in a note and storing it as a coded medication entry).

There is a clear need for such \textbf{structured information extraction} to make use of the rich data in clinical notes. Studies have noted that much of the patient information needed for clinical decision support and quality improvement is locked in free-text form \parencite{Liu2024}. Automating the extraction of diagnoses, symptoms, medications, and other entities from text would enable these data to be integrated with existing structured EHR fields. This, in turn, supports advanced applications: for example, clinical decision support tools could alert providers to issues noted in narrative history that might otherwise be overlooked, and researchers could aggregate real-world evidence from clinical notes at scale. Indeed, combining structured and unstructured data has been shown to improve the performance of predictive models and diagnostic algorithms, since narrative notes often contain context (like lifestyle factors or symptom nuances) not found elsewhere.

In summary, the motivation is that \textbf{structured representation of information yields more actionable and computable data}. Rather than leaving free-text data underutilized, converting it into structured form (through IE and encoding) can facilitate interoperability and analysis. This thesis is driven by the recognition that developing robust methods to extract structured knowledge from unstructured clinical text will significantly enhance our ability to leverage EHR data for patient care and biomedical insights.

\subsection{Graph Databases for Healthcare Data}

Once information is extracted from text, an appropriate data representation is needed to organize and utilize it effectively. \textbf{Knowledge graphs} (implemented via graph databases) have emerged as a powerful paradigm for representing complex interconnected information in healthcare. A knowledge graph consists of nodes (entities such as patients, clinical concepts, etc.) and edges (relationships between entities), forming a network of facts. This graph-based model aligns well with healthcare data, which is inherently relational and heterogeneous. For instance, consider a patient who has multiple conditions, treatments, and care providers – a graph can naturally capture these many-to-many relationships (Patient–diagnosed\_with–Condition; Patient–treated\_with–Drug; Physician–prescribes–Drug; and so on) in a way that a traditional relational database struggles to without complex joint tables.

Graph database technology (such as Neo4j, an industry-leading graph DB) is \textbf{well-suited for modeling and querying complex, relationship-centric data} in healthcare. Unlike rigid relational schemas, graphs offer flexibility: new entity types or relationship types can be added without altering a global schema, and irregular data (which is common in clinical records) can be accommodated. Moreover, querying a knowledge graph (e.g. finding all patients who had a certain combination of symptoms before a diagnosis) can be more intuitive, as graph query languages like Cypher allow traversing connections in the data. The ability to \textbf{efficiently traverse interconnected data} is ideal for healthcare analytics where we might seek paths or networks of associations (for example, tracing a patient's journey through various diagnoses and interventions, or identifying clusters of related medical conditions).

Another key motivation for using knowledge graphs is their support for \textbf{explainable decision support} in clinical settings. By organizing medical knowledge as a graph of entities and relationships, one can build decision support systems that not only provide recommendations but also trace the chain of linked information that led to those recommendations. For example, a knowledge graph might help a clinician understand that a suggested treatment is linked to a diagnosis through published guidelines or patient history nodes in the graph. Previous research has demonstrated that integrating EHR data into knowledge graphs enhances complex reasoning and allows clinicians to query patient data in more meaningful ways \parencite{Rotmensch2017}. Graph-based representations can unify data from fragmented sources (different hospitals or departments) and still preserve the connections needed for a holistic view of the patient.

In summary, \textbf{graph databases provide the infrastructure to turn extracted facts into an "actionable" knowledge network}. By storing the output of information extraction in a knowledge graph, this research enables sophisticated queries, visualizations of patient data relationships, and improved decision support capabilities that leverage the full context of a patient's record.

%----------------------------------------------------------------------------------------

\section{Research Question and Objectives}

\subsection{Primary Research Question}

The primary question driving this thesis is:

\textbf{How can unstructured clinical text be transformed into an actionable knowledge graph using a multi-model approach for information extraction in healthcare?}

In essence, we seek to determine the methods by which narrative clinical documents (e.g. doctor's notes, discharge summaries) can be automatically analyzed to extract structured knowledge – such as medical entities and the relationships between them – and how this extracted information can be represented in a knowledge graph that is useful for clinical or analytical purposes. This research question encompasses the development of a pipeline that leverages multiple models (for example, specialized models for named entity recognition, entity linking, and relationship extraction) and the evaluation of that pipeline's effectiveness. The focus is on achieving a transformation that is both \textbf{accurate} (correctly capturing the information in text) and \textbf{actionable}, meaning the resulting knowledge graph can support real-world use cases like querying patient information or powering decision support tools.

\subsection{Specific Objectives}

To address the primary research question, the following specific objectives are defined:

\begin{enumerate}
\item \textbf{Design and implement a multi-model NLP pipeline for clinical text.} This involves combining a named entity recognition (NER) model with an entity linking mechanism and a relationship extraction model to process unstructured clinical notes. The pipeline should identify key medical entities (such as diseases, medications, symptoms) and the relationships between them from free text.

\item \textbf{Leverage both domain-specific and general language models for information extraction.} We will integrate a medical-domain pretrained model (for example, a specialized clinical language model) and compare it with a general-purpose language model for extracting relationships in text. The objective is to evaluate whether a domain-tuned model (referred to as \emph{MedGemma} in this work) provides superior accuracy in clinical relationship extraction compared to a general model (\emph{Gemma}), thereby informing model selection for knowledge graph construction.

\item \textbf{Construct an actionable healthcare knowledge graph from extracted information.} Using the entities and relations identified by the pipeline, build a knowledge graph using a graph database (Neo4j). This includes defining an appropriate graph schema (nodes, relationships, properties) and automatically translating extraction outputs into graph database queries (Cypher queries) that populate the knowledge graph. The resulting graph should represent the content of clinical notes in a structured form that can be queried for insights.

\item \textbf{Ensure compliance with privacy and ethical standards in handling clinical data.} Implement data de-identification and privacy-preserving techniques throughout the pipeline so that no personally identifiable information (PII) or protected health information (PHI) is exposed in the process of information extraction or in the constructed knowledge graph. This objective is crucial given the sensitive nature of clinical text.

\item \textbf{Evaluate the performance and utility of the proposed approach.} Develop an evaluation framework to measure the accuracy of the named entity recognition and relationship extraction components (for example, using precision, recall, and F1 metrics on an annotated dataset). Additionally, evaluate the quality of the generated knowledge graph (e.g., correctness of triples, coverage of information, query performance). A comparative analysis will be conducted between the domain-specific and general models to quantify their impact on relationship extraction accuracy and the downstream knowledge graph completeness. This objective also involves performing error analysis to understand common failure modes and conducting statistical significance testing on the results to ensure robustness of conclusions.
\end{enumerate}

Through these objectives, the thesis systematically addresses the problem of converting unstructured clinical text into a structured knowledge graph, from methodological development to evaluation of outcomes.

%----------------------------------------------------------------------------------------

\section{Ethical Considerations and Data Privacy}

\subsection{Handling Sensitive Clinical Information}

Clinical text data contains sensitive personal health information, so any processing of such data must rigorously protect patient privacy. A fundamental step is \textbf{de-identification} of the clinical documents used in this research. De-identification involves removing or obscuring all direct identifiers and quasi-identifiers that could link back to individual patients. According to guidelines like the HIPAA Privacy Rule's Safe Harbor standard, this includes removing 18 types of identifiers such as names, dates of birth, contact information, and medical record numbers. In this thesis, all clinical notes are assumed to be de-identified prior to processing; any remaining identifiers (like hospital names or doctor names) are handled by either filtering them out or replacing them with surrogate tokens. This ensures that the text data used for model development and the resulting knowledge graph do not contain real patient identities.

Beyond removing identifiers, careful handling of data is observed. All computing is done in secure environments and \textbf{data governance} principles are followed to limit the use of the data strictly to the stated research objectives. Because the thesis is written and conducted in English, we also ensure that the dataset contains only English content. By taking these precautions, we prioritize the confidentiality of patient information throughout the research.

\subsection{Privacy-Preserving Techniques}

In addition to basic de-identification, \textbf{privacy risk assessments} are performed to ensure that no combination of outputs could inadvertently reveal patient identity \parencite{Ali2024}. This includes analyzing the knowledge graph triples to confirm they do not contain identifiable details. Any intermediate data that contained potentially sensitive information (for example, original text spans of notes) is not stored persistently in the knowledge graph – only the extracted medical facts (which are general clinical concepts) are stored. By employing and planning for these privacy-preserving strategies, the research upholds ethical standards while still enabling valuable analysis of clinical text.

%----------------------------------------------------------------------------------------

\section{Thesis Contributions}

This thesis makes several contributions to the field of clinical NLP and healthcare knowledge management:

\begin{itemize}
\item \textbf{Integrated Multi-Model Extraction Pipeline:} We develop a novel pipeline that integrates multiple NLP models to transform unstructured clinical text into a structured knowledge graph. In particular, the pipeline combines a state-of-the-art medical named entity recognizer with an entity linking component (grounding entities to an external knowledge base) and a relation extraction module powered by large language models. This integrated approach demonstrates how various tools can be orchestrated to perform end-to-end clinical information extraction.

\item \textbf{Domain-Specific vs. General Language Model Comparison:} The research provides an in-depth comparative analysis of a domain-specific model (\emph{MedGemma}, pretrained on medical text) versus a general-purpose model (\emph{Gemma}) for the task of extracting relationships from clinical narratives. We quantify their respective strengths and weaknesses on relationship extraction accuracy and downstream knowledge graph quality. This contribution offers insights into the value of domain specialization in large language models for healthcare applications.

\item \textbf{Construction of an Actionable Clinical Knowledge Graph:} The thesis presents the design and implementation of a healthcare knowledge graph that captures the content of clinical notes in a machine-readable form. We contribute a methodology for translating raw text into graph database entries, including a schema tailored to clinical data (covering patients, clinical entities, and relations). The resulting knowledge graph is evaluated for its ability to answer complex clinical queries, illustrating the practical utility of converting text into a graph format.

\item \textbf{Empirical Evaluation and Open Insights:} We conduct comprehensive experiments to evaluate each component of the system (NER, entity linking, relation extraction) as well as the final knowledge graph. The thesis reports detailed results, including error analyses and case studies, which shed light on common challenges in clinical information extraction \parencite{Hier2025}. These empirical findings contribute to the broader understanding of what approaches work well (and where difficulties remain) in transforming EHR data into structured knowledge. All findings are discussed in the context of existing literature, thereby highlighting how our approach advances the state of the art or addresses noted gaps.
\end{itemize}

Through the above contributions, the thesis advances both the methodology for clinical information extraction and the practical considerations for deploying such techniques in real healthcare contexts.