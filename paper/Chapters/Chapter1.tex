% Chapter 1

\chapter{Introduction} % Main chapter title

\label{Chapter1} % For referencing the chapter elsewhere, use \ref{Chapter1} 

%----------------------------------------------------------------------------------------

% Define some commands to keep the formatting separated from the content 
\newcommand{\keyword}[1]{\textbf{#1}}
\newcommand{\tabhead}[1]{\textbf{#1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\file}[1]{\texttt{\bfseries#1}}
\newcommand{\option}[1]{\texttt{\itshape#1}}

%----------------------------------------------------------------------------------------

\section{Background and Context}

\subsection{Biomedical Text and Knowledge Sources}

The biomedical domain generates vast amounts of textual data through multiple channels including electronic health records (EHRs), scientific literature, and research databases \parencite{Kong2019}. This biomedical text comes in both \textbf{structured} and \textbf{unstructured} formats. Structured data refers to information stored in predefined fields (e.g. patient demographics, clinical codes, genomic sequences, chemical formulas) that can be readily queried. In contrast, \textbf{unstructured data} consists of free-form text such as clinical narratives, research abstracts, full-text articles, case reports, and experimental descriptions. Free-text biomedical documents are a natural and comprehensive way for healthcare providers and researchers to communicate complex medical knowledge, often capturing nuanced relationships between biomedical entities that do not fit neatly into structured fields \parencite{Laue2024}. For example, a research abstract may describe novel drug-disease interactions or a physician's note may document symptom severity in richer detail than any standardized code.

Notably, unstructured content constitutes the majority of biomedical documentation. By some estimates, \textbf{up to 80\% of healthcare and biomedical data is unstructured} text \parencite{Kong2019}. This includes clinical notes, research publications (PubMed contains over 35 million citations), experimental protocols, and case studies that do not reside in tabular databases but in narrative form. Such unstructured biomedical text is immensely valuable, as it provides comprehensive documentation of clinical reasoning, experimental findings, and scientific discoveries. However, because it lacks a predefined format, unstructured data is not directly usable by computers or standard query tools. Healthcare organizations and researchers are therefore faced with the challenge of leveraging these abundant textual documents to improve patient care, accelerate research, and enable evidence-based decision-making.

\subsection{Challenges with Unstructured Biomedical Text}

Working with unstructured biomedical text is inherently challenging. Free-text biomedical documents are \textbf{difficult for automated systems to interpret} due to their lack of consistent structure and the complexities of scientific and clinical language \parencite{Stenetorp2024}. Unlike structured database entries, biomedical text may contain context-dependent information, ambiguous terminology, and diverse writing styles across different domains (clinical, research, pharmaceutical). Indeed, biomedical text often includes \textbf{domain-specific abbreviations, technical jargon, complex chemical names, and variable nomenclature}, all of which increase the difficulty of parsing and analyzing the data. Important relationships might be embedded in complex sentence structures, making it hard to extract specific entity interactions without advanced text processing. As a result, analyzing unstructured biomedical literature has traditionally required labor-intensive manual review by domain experts or limited rule-based systems.

Another challenge is the inherent variability and complexity of biomedical language across different contexts. Research articles are not written with standardized vocabulary usage; different authors may describe the same biological process or clinical concept in varied ways. Moreover, biomedical text reflects the complexity of biological systems with their multifaceted interactions. In contrast to controlled vocabularies like medical ontologies, \textbf{biomedical literature presents irregular, multifaceted data}: biological entities often have multiple functions and interactions, and publications may discuss both established and novel findings. The technical style, specialized terminology, and the fact that findings are presented through different research perspectives make consistent information extraction problematic. These factors can confound algorithms attempting to identify entities (such as genes, diseases, or chemical compounds) and their relationships from raw text.

In addition, \textbf{scale and integration issues} pose further hurdles. The biomedical literature grows exponentially with thousands of new papers published daily \parencite{Kong2019}, leading to information overload; processing this volume is complex and time-consuming. The heterogeneity of data sources (research articles, clinical notes, patents, databases, etc.) adds complexity in combining unstructured with structured biomedical data. Data quality issues like inconsistent entity mentions or missing context can propagate errors in analysis. All these challenges underscore why much of the unstructured biomedical text remains underutilized for systematic knowledge discovery. However, given the wealth of knowledge contained in biomedical literature, there is strong incentive to overcome these difficulties through advanced computational methods. In recent years, the field of \textbf{biomedical natural language processing (NLP)} has gained wide interest as researchers apply machine learning and language models to parse and derive meaning from biomedical text. These developments set the stage for transforming unstructured biomedical documents into structured forms that can drive scientific insights and clinical applications.

%----------------------------------------------------------------------------------------

\section{Research Motivation}

\subsection{The Need for Structured Information Extraction}

Unlocking the value in unstructured biomedical text is a key motivation for this research. While researchers and clinicians rely on narrative documentation for communication and knowledge sharing, secondary use of this data (for systematic analysis, knowledge discovery, or automated reasoning) is limited by its unstructured nature. In order for biomedical information systems to fully utilize the vast literature and clinical documentation, the free-text portions must be converted into a structured, machine-readable form. \textbf{Information Extraction (IE)} is the crucial NLP task aimed at addressing this gap: it automatically identifies and encodes important pieces of information from unstructured text. By applying IE to biomedical literature, one can populate databases or knowledge bases with structured representations of scientific findings (e.g. identifying gene-disease associations mentioned in research abstracts and storing them as relationship triples in a knowledge graph).

There is a clear need for such \textbf{structured information extraction} to make use of the rich knowledge in biomedical texts. Studies have noted that much of the biomedical knowledge needed for drug discovery, clinical decision support, and research hypothesis generation is locked in free-text form \parencite{Liu2024}. Automating the extraction of entities (genes, diseases, chemicals, species) and their relationships from biomedical literature would enable this knowledge to be integrated with existing structured databases and ontologies. This, in turn, supports advanced applications: for example, drug discovery systems could identify novel therapeutic targets from literature that might otherwise be overlooked, and researchers could systematically aggregate evidence from thousands of clinical notes and publications to generate new hypotheses. Indeed, combining structured and unstructured biomedical data has been shown to improve the performance of predictive models and knowledge discovery systems, since literature often contains context and novel findings not yet captured in databases.

In summary, the motivation is that \textbf{structured representation of information yields more actionable and computable knowledge}. Rather than leaving free-text biomedical data underutilized, converting it into structured form (through IE and encoding) can facilitate systematic analysis and knowledge discovery. This thesis is driven by the recognition that developing robust methods to extract structured knowledge from unstructured biomedical text will significantly enhance our ability to leverage scientific literature for research acceleration and clinical insights.

\subsection{Graph Databases for Biomedical Knowledge}

Once information is extracted from text, an appropriate data representation is needed to organize and utilize it effectively. \textbf{Knowledge graphs} (implemented via graph databases) have emerged as a powerful paradigm for representing complex interconnected information in biomedicine \parencite{Milvus2025}. A knowledge graph consists of nodes (entities such as genes, diseases, chemical compounds, species, etc.) and edges (relationships between entities), forming a network of facts. This graph-based model aligns well with biomedical knowledge, which is inherently relational and heterogeneous. For instance, consider a disease that involves multiple genes, is treated by various drugs, and affects different biological pathways – a graph can naturally capture these many-to-many relationships (Gene→associated\_with→Disease; Drug→treats→Disease; Disease→affects→Pathway; and so on) in a way that traditional relational databases struggle to represent without complex join tables.

Another key motivation for using knowledge graphs is their support for \textbf{knowledge discovery and hypothesis generation} in biomedical research. By organizing biomedical knowledge as a graph of entities and relationships, researchers can build systems that not only retrieve information but also discover novel connections through graph traversal and reasoning. For example, a knowledge graph might help researchers identify potential drug repurposing opportunities by finding paths connecting known drugs to diseases through shared molecular targets or biological pathways. Previous research has demonstrated that integrating biomedical literature into knowledge graphs enhances complex reasoning and allows researchers to query scientific knowledge in more meaningful ways \parencite{Rotmensch2017}. Graph-based representations can unify knowledge from fragmented sources (different publications, databases, clinical records) and still preserve the connections needed for comprehensive biomedical understanding.

In summary, \textbf{graph databases provide the infrastructure to turn extracted biomedical facts into an "actionable" knowledge network}. By storing the output of information extraction in a knowledge graph, this research enables sophisticated queries, visualization of biomedical relationships, and improved knowledge discovery capabilities that leverage the full context of scientific literature and clinical data.

%----------------------------------------------------------------------------------------

\section{Research Question and Objectives}

\subsection{Primary Research Question}

The primary question driving this thesis is:

\textbf{How can unstructured biomedical text be transformed into an actionable knowledge graph using a multi-model approach for information extraction in healthcare and biomedical research?}

We seek to determine how biomedical documents (e.g., research abstracts, clinical notes, scientific articles) can be automatically analyzed to extract structured knowledge and represented in a useful knowledge graph. This encompasses developing a multi-model pipeline (specialized models for entity recognition, linking, and relationship extraction) and evaluating its effectiveness. The focus is achieving a transformation that is both \textbf{accurate} and \textbf{actionable} for real-world use cases like knowledge discovery, literature analysis, and biomedical research acceleration.

\subsection{Specific Objectives}

To address the primary research question, the following specific objectives are defined:

\begin{enumerate}
  \item \textbf{Design and implement a multi-model NLP pipeline for biomedical text.} This involves combining a named entity recognition (NER) model with entity linking and relationship extraction to process unstructured biomedical literature, identifying key biomedical entities (genes, diseases, chemicals, species) and their relationships from free text.

  \item \textbf{Leverage both domain-specific and general language models for information extraction.} We will compare a medical domain-specific pretrained model (\emph{MedGemma}) with a general-purpose model (\emph{Gemma}) for extracting relationships, evaluating whether domain-specific fine-tuning provides superior accuracy in biomedical relationship extraction.

  \item \textbf{Construct an actionable biomedical knowledge graph from extracted information.} Using identified entities and relations, build a knowledge graph in Neo4j by defining appropriate schema and automatically translating extraction outputs into Cypher queries that populate a structured, queryable representation of biomedical literature.

  \item \textbf{Ensure compliance with ethical standards and data usage policies.} Implement appropriate data handling practices throughout the pipeline, ensuring proper citation and usage of public biomedical datasets while maintaining research integrity and following established guidelines for biomedical text mining.

  \item \textbf{Evaluate the performance and utility of the proposed approach.} Develop evaluation frameworks measuring NER and relationship extraction accuracy using precision, recall, and F1 metrics against gold-standard biomedical datasets, plus knowledge graph quality assessment. Compare domain-specific versus general models through statistical analysis to quantify their impact on extraction accuracy and graph completeness.
\end{enumerate}

Through these objectives, the thesis systematically addresses the problem of converting unstructured biomedical text into a structured knowledge graph, from methodological development to evaluation of outcomes.

%----------------------------------------------------------------------------------------

\section{Ethical Considerations and Data Privacy}

\subsection{Responsible Use of Biomedical Data}

Biomedical text data encompasses both publicly available scientific literature and sensitive clinical information, requiring careful attention to ethical standards and privacy protection. While research literature is generally publicly accessible, clinical text contains sensitive personal health information that demands rigorous privacy safeguards. For any clinical data processing, a fundamental step is \textbf{de-identification} to remove or obscure all identifiers that could link back to individual patients, following guidelines like the HIPAA Privacy Rule's Safe Harbor standard.

In this research, we primarily utilize publicly available biomedical datasets such as \textbf{BioRED} \parencite{BioRED}, which contains scientific abstracts from PubMed that do not contain personal health information. These datasets are obtained through legitimate research channels and used according to their intended research applications. However, our methodology is designed to be applicable to clinical data as well, with appropriate privacy protections. Any clinical text would be assumed to be properly de-identified prior to processing, with remaining institutional identifiers handled through filtering or tokenization to ensure no real patient or provider identities are exposed.

\textbf{Data governance} principles are followed throughout, limiting data use strictly to stated research objectives of developing and evaluating biomedical information extraction methods. We maintain research integrity by properly citing all data sources and following established protocols for biomedical text mining. The focus remains on extracting general biomedical knowledge patterns rather than identifying specific individuals or sensitive information. Because the thesis is conducted in English, we ensure all datasets contain English-language content suitable for our methodological approach.

%----------------------------------------------------------------------------------------

\section{Thesis Contributions}

This thesis makes several contributions to the field of biomedical NLP and healthcare knowledge management:

\begin{itemize}
  \item \textbf{Integrated Multi-Model Extraction Pipeline:} We develop a novel pipeline integrating multiple NLP models to transform unstructured biomedical text into structured knowledge graphs. The pipeline combines biomedical named entity recognition, entity linking to external knowledge bases, and relation extraction using large language models, demonstrating orchestrated end-to-end biomedical information extraction.

  \item \textbf{Domain-Specific vs. General Language Model Comparison:} The research provides comparative analysis of a domain-specific model (\emph{MedGemma}) versus a general-purpose model (\emph{Gemma}) for extracting relationships from biomedical literature. We quantify their strengths and weaknesses on relationship extraction accuracy and knowledge graph quality, offering insights into domain specialization value for biomedical and healthcare applications.

  \item \textbf{Construction of an Actionable Biomedical Knowledge Graph:} The thesis presents design and implementation of a biomedical knowledge graph capturing scientific literature in machine-readable form. We contribute methodology for translating raw biomedical text into graph database entries with domain-tailored schema, evaluating the graph's ability to answer complex biomedical queries and demonstrating practical utility for knowledge discovery.

  \item \textbf{Empirical Evaluation and Open Insights:} We conduct comprehensive experiments evaluating each system component and the final knowledge graph using established biomedical benchmarks like BioRED \parencite{BioRED}. The thesis reports detailed results, error analyses, and case studies illuminating common challenges in biomedical information extraction \parencite{Hier2025}, contributing to broader understanding of effective approaches and remaining difficulties in transforming biomedical literature into structured knowledge.
\end{itemize}

Through the above contributions, the thesis advances both the methodology for biomedical information extraction and the practical considerations for deploying such techniques in real biomedical research and healthcare contexts.