% Chapter 1

\chapter{Introduction} % Main chapter title

\label{Chapter1} % For referencing the chapter elsewhere, use \ref{Chapter1} 

%----------------------------------------------------------------------------------------

% Define some commands to keep the formatting separated from the content 
\newcommand{\keyword}[1]{\textbf{#1}}
\newcommand{\tabhead}[1]{\textbf{#1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\file}[1]{\texttt{\bfseries#1}}
\newcommand{\option}[1]{\texttt{\itshape#1}}

%----------------------------------------------------------------------------------------

\section{Background and Context}

\subsection{Clinical Documentation in Healthcare}

Healthcare providers generate vast amounts of data through electronic health records (EHRs), which serve as longitudinal digital records of patient information. EHR data comes in both \textbf{structured} and \textbf{unstructured} formats. Structured data refers to information stored in predefined fields (e.g. patient demographics, vital signs, lab results, diagnoses, medications) that can be readily queried. In contrast, \textbf{unstructured data} consists of free-form text and other formats such as clinical narratives, discharge summaries, radiology reports, and even medical images. Free-text clinical notes are a natural and expressive way for clinicians to document patient encounters, often capturing nuanced details of a patient's condition and care that do not fit neatly into structured fields. For example, a physician's narrative note may describe symptom severity or social circumstances in richer detail than any diagnostic code.

Notably, unstructured content constitutes the majority of clinical documentation. By some estimates, \textbf{up to 80\% of healthcare data is unstructured} text or images \parencite{Kong2019}. This means that most recorded medical information—such as physician notes, operative reports, and imaging studies—does not reside in tabular databases but in narrative form. Such unstructured clinical documentation is immensely valuable, as it provides a ``glimpse into the physician's brain,'' revealing clinical reasoning and context beyond what structured data can convey. However, because it lacks a predefined format, unstructured data is not directly usable by computers or standard query tools. Healthcare organizations are therefore faced with the challenge of leveraging these abundant narrative documents to improve patient care, research, and decision-making.

\subsection{Challenges with Unstructured Clinical Data}

Working with unstructured clinical text is inherently challenging. Free-text medical notes are \textbf{difficult for automated systems to interpret} due to their lack of consistent structure and the complexities of natural language. Unlike structured entries, a narrative note may contain context-dependent information, ambiguous terminology, and diverse writing styles. Indeed, clinical text often includes \textbf{misspellings, grammatical errors, shorthand and abbreviations, and incomplete sentences}, all of which increase the difficulty of parsing and analyzing the data. Important details might be embedded in long narrative paragraphs, making it hard to extract specific facts without advanced text processing. As a result, analyzing unstructured EHR data has traditionally required labor-intensive manual review or bespoke rule-based systems.

Another challenge is the inherent variability and informality of clinical language in practice. Clinical notes are not written with standardized vocabulary or ontology usage; different clinicians may describe the same concept in varied ways. Moreover, notes reflect real-world patient cases with all their complexity. In contrast to controlled text like medical textbooks, \textbf{EHR narratives present irregular, multifaceted data}: patients often have multiple comorbidities, and documentation may intermix relevant and irrelevant details. The informal style (e.g. telegraphic phrases, local acronyms) and the fact that observations are filtered through each clinician's perspective make consistent information extraction problematic. These factors can confound algorithms attempting to identify entities (such as diseases or medications) and their relationships from raw text.

In addition, \textbf{scale and integration issues} pose further hurdles. Hospitals generate hundreds of notes per day, leading to information overload; processing this volume is complex and time-consuming. The heterogeneity of data sources (notes, images, labs, etc.) adds complexity in combining unstructured with structured data. Data quality issues like typos or missing context can propagate errors in analysis. All these challenges underscore why much of the unstructured clinical data remains underutilized. However, given the wealth of knowledge contained in narrative texts, there is strong incentive to overcome these difficulties through advanced computational methods. In recent years, the field of \textbf{clinical natural language processing (NLP)} has gained wide interest as researchers apply machine learning and language models to parse and derive meaning from clinical text. These developments set the stage for transforming unstructured clinical documents into structured forms that can drive insights.

%----------------------------------------------------------------------------------------

\section{Research Motivation}

\subsection{The Need for Structured Information Extraction}

Unlocking the value in unstructured clinical text is a key motivation for this research. While clinicians rely on narrative documentation for communication and decision recording, secondary use of this data (for analytics, decision support, or research) is limited by its unstructured nature. In order for healthcare information systems to fully utilize EHR data, the free-text portions must be converted into a structured, machine-readable form. \textbf{Information Extraction (IE)} is the crucial NLP task aimed at addressing this gap: it automatically identifies and encodes important pieces of information from unstructured text. By applying IE to clinical narratives, one can populate databases or knowledge bases with structured representations of the same information (e.g. identifying a drug name and dosage mentioned in a note and storing it as a coded medication entry).

There is a clear need for such \textbf{structured information extraction} to make use of the rich data in clinical notes. Studies have noted that much of the patient information needed for clinical decision support and quality improvement is locked in free-text form \parencite{Liu2024}. Automating the extraction of diagnoses, symptoms, medications, and other entities from text would enable these data to be integrated with existing structured EHR fields. This, in turn, supports advanced applications: for example, clinical decision support tools could alert providers to issues noted in narrative history that might otherwise be overlooked, and researchers could aggregate real-world evidence from clinical notes at scale. Indeed, combining structured and unstructured data has been shown to improve the performance of predictive models and diagnostic algorithms, since narrative notes often contain context (like lifestyle factors or symptom nuances) not found elsewhere.

In summary, the motivation is that \textbf{structured representation of information yields more actionable and computable data}. Rather than leaving free-text data underutilized, converting it into structured form (through IE and encoding) can facilitate interoperability and analysis. This thesis is driven by the recognition that developing robust methods to extract structured knowledge from unstructured clinical text will significantly enhance our ability to leverage EHR data for patient care and biomedical insights.

\subsection{Graph Databases for Healthcare Data}

Once information is extracted from text, an appropriate data representation is needed to organize and utilize it effectively. \textbf{Knowledge graphs} (implemented via graph databases) have emerged as a powerful paradigm for representing complex interconnected information in healthcare. A knowledge graph consists of nodes (entities such as patients, clinical concepts, etc.) and edges (relationships between entities), forming a network of facts. This graph-based model aligns well with healthcare data, which is inherently relational and heterogeneous. For instance, consider a patient who has multiple conditions, treatments, and care providers – a graph can naturally capture these many-to-many relationships (Patient–diagnosed\_with–Condition; Patient–treated\_with–Drug; Physician–prescribes–Drug; and so on) in a way that a traditional relational database struggles to without complex joint tables.

Another key motivation for using knowledge graphs is their support for \textbf{explainable decision support} in clinical settings. By organizing medical knowledge as a graph of entities and relationships, one can build decision support systems that not only provide recommendations but also trace the chain of linked information that led to those recommendations. For example, a knowledge graph might help a clinician understand that a suggested treatment is linked to a diagnosis through published guidelines or patient history nodes in the graph. Previous research has demonstrated that integrating EHR data into knowledge graphs enhances complex reasoning and allows clinicians to query patient data in more meaningful ways \parencite{Rotmensch2017}. Graph-based representations can unify data from fragmented sources (different hospitals or departments) and still preserve the connections needed for a holistic view of the patient.

In summary, \textbf{graph databases provide the infrastructure to turn extracted facts into an "actionable" knowledge network}. By storing the output of information extraction in a knowledge graph, this research enables sophisticated queries, visualizations of patient data relationships, and improved decision support capabilities that leverage the full context of a patient's record.

%----------------------------------------------------------------------------------------

\section{Research Question and Objectives}

\subsection{Primary Research Question}

The primary question driving this thesis is:

\textbf{How can unstructured clinical text be transformed into an actionable knowledge graph using a multi-model approach for information extraction in healthcare?}

We seek to determine how narrative clinical documents (e.g., doctor's notes, discharge summaries) can be automatically analyzed to extract structured knowledge and represented in a useful knowledge graph. This encompasses developing a multi-model pipeline (specialized models for entity recognition, linking, and relationship extraction) and evaluating its effectiveness. The focus is achieving a transformation that is both \textbf{accurate} and \textbf{actionable} for real-world use cases like querying patient information or powering decision support tools.

\subsection{Specific Objectives}

To address the primary research question, the following specific objectives are defined:

\begin{enumerate}
  \item \textbf{Design and implement a multi-model NLP pipeline for clinical text.} This involves combining a named entity recognition (NER) model with entity linking and relationship extraction to process unstructured clinical notes, identifying key medical entities and their relationships from free text.

  \item \textbf{Leverage both domain-specific and general language models for information extraction.} We will compare a medical domain-specific pretrained model (\emph{MedGemma}) with a general-purpose model (\emph{Gemma}) for extracting relationships, evaluating whether domain-specific fine-tuning provides superior accuracy in clinical relationship extraction.

  \item \textbf{Construct an actionable healthcare knowledge graph from extracted information.} Using identified entities and relations, build a knowledge graph in Neo4j by defining appropriate schema and automatically translating extraction outputs into Cypher queries that populate a structured, queryable representation of clinical notes.

  \item \textbf{Ensure compliance with privacy and ethical standards in handling clinical data.} Implement data de-identification and privacy-preserving techniques throughout the pipeline to prevent exposure of personally identifiable information (PII) or protected health information (PHI) during extraction or graph construction.

  \item \textbf{Evaluate the performance and utility of the proposed approach.} Develop evaluation frameworks measuring NER and relationship extraction accuracy using precision, recall, and F1 metrics, plus knowledge graph quality assessment. Compare domain-specific versus general models through statistical analysis to quantify their impact on extraction accuracy and graph completeness.
\end{enumerate}

Through these objectives, the thesis systematically addresses the problem of converting unstructured clinical text into a structured knowledge graph, from methodological development to evaluation of outcomes.

%----------------------------------------------------------------------------------------

\section{Ethical Considerations and Data Privacy}

\subsection{Handling Sensitive Clinical Information}

Clinical text data contains sensitive personal health information, so any processing of such data must rigorously protect patient privacy. A fundamental step is \textbf{de-identification} of the clinical documents used in this research. De-identification involves removing or obscuring all direct identifiers and quasi-identifiers that could link back to individual patients. According to guidelines like the HIPAA Privacy Rule's Safe Harbor standard, this includes removing 18 types of identifiers such as names, dates of birth, contact information, and medical record numbers. In this thesis, all clinical notes are assumed to be de-identified prior to processing; any remaining identifiers (like hospital names or doctor names) are handled by either filtering them out or replacing them with surrogate tokens. This ensures that the text data used for model development and the resulting knowledge graph do not contain real patient identities. Also \textbf{data governance} principles are followed to limit the use of the data strictly to the stated research objectives. Because the thesis is written and conducted in English, we also ensure that the dataset contains only English content.

%----------------------------------------------------------------------------------------

\section{Thesis Contributions}

This thesis makes several contributions to the field of clinical NLP and healthcare knowledge management:

\begin{itemize}
  \item \textbf{Integrated Multi-Model Extraction Pipeline:} We develop a novel pipeline integrating multiple NLP models to transform unstructured clinical text into structured knowledge graphs. The pipeline combines medical named entity recognition, entity linking to external knowledge bases, and relation extraction using large language models, demonstrating orchestrated end-to-end clinical information extraction.

  \item \textbf{Domain-Specific vs. General Language Model Comparison:} The research provides comparative analysis of a domain-specific model (\emph{MedGemma}) versus a general-purpose model (\emph{Gemma}) for extracting relationships from clinical narratives. We quantify their strengths and weaknesses on relationship extraction accuracy and knowledge graph quality, offering insights into domain specialization value for healthcare applications.

  \item \textbf{Construction of an Actionable Clinical Knowledge Graph:} The thesis presents design and implementation of a healthcare knowledge graph capturing clinical notes in machine-readable form. We contribute methodology for translating raw text into graph database entries with clinical-tailored schema, evaluating the graph's ability to answer complex clinical queries and demonstrating practical utility.

  \item \textbf{Empirical Evaluation and Open Insights:} We conduct comprehensive experiments evaluating each system component and the final knowledge graph. The thesis reports detailed results, error analyses, and case studies illuminating common challenges in clinical information extraction \parencite{Hier2025}, contributing to broader understanding of effective approaches and remaining difficulties in transforming EHR data into structured knowledge.
\end{itemize}

Through the above contributions, the thesis advances both the methodology for clinical information extraction and the practical considerations for deploying such techniques in real healthcare contexts.